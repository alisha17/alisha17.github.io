---
layout: post
title: "[MLAI Meetup Talk] My Experience as a Machine Learning Intern"
categories: [Silverpond]
comments: true
---

I started my internship at SilverPond as a Machine Learning Engineer in September.

This is me at SilverPond :)

![pizzer]({{ site.url }}/assets/image1.jpeg)

I spent initial few weeks getting familiar with Silverbrane. Silverbrane is an amazing Machine Learning product developed by an amazing team at SilverPond which combines optimised expert-driven tooling with AI, which in brief does this:

![pizzeria hde3]({{ site.url }}/assets/silverbrane.png)

# Project 1:

My first project was “Server provisioning in Silverbrane”. I had to provision the server to automatically spin the workers to start training the model, which was previously a manual process.

By the end of it, I learnt about:

* Managing AWS ec2 instances using console
* Managing AWS ec2 instances using programming (using aws-sdk for ruby)
* How Ruby on Rails project is structured
* Finding my way inside a rails project (Though I still don’t understand Rails or Ruby much!)

# Project 2:

At the moment, I am working on an another project in which we “Count the number of cars in overhead imagery with deep learning”. This project tries to replicate the results presented in this paper: [Mundhenk et al. 2016](https://gdo-datasci.ucllnl.org/cowc/mundhenk_et_al_eccv_2016.pdf)

Vehicle localization from satellite imagery has myriad use cases in the commercial, national security, and humanitarian realms. On the commercial front, a number of companies have attempted to infer retail traffic from parking lot density levels, and tracking delivery trucks in near real-time is one of the far-field goals of satellite imagery analytics. In the realm of national security, detecting the buildup of war materiel in unstable regions would provide obvious value, as would locating convoys of vehicles vectored towards unmanned border crossings, or identifying a large number of vehicles staging just outside the range of terrestrial border monitoring equipment. On the humanitarian front, one might attempt to infer the scope of natural disasters from clusters (or absences) of vehicles, or determine optimal travel routes for disaster relief in unknown areas based on observations of local vehicle movements.
Dataset

The dataset consists of large number of unique cars (~33,000) from six different imagesets, where each imageset has more than 60,000 images. Each imageset covers a different geographical location and produced by different imagers and has different training and test sets. The regions are Toronto Canada, Selwyn New Zealand, Potsdam & Vaihingen Germany, Columbus & Utah United States. Data is collected via aerial platforms, but at a view angle such that it resembles satellite imagery. The imagery has a resolution of 15 cm ground sample distance (GSD) that is approximately twice as good as the current best resolution of commercial satellite imagery.

Dataset consists of images like these:

![pizzeria hde3]({{ site.url }}/assets/null1.png)
![pizzeria hde3]({{ site.url }}/assets/null3.png)


## Approach:

* I started by using inception model to classify the images, though it is not really good at classifying correctly, since it is a baseline model. I downloaded a pre-trained inception model, since it takes weeks to train on a monster computer with 8 Tesla K40 GPUs costing ~$30,000 so it is impossible to train it on an ordinary PC.
* I trained the model by logistic regression using scikit-learn. It is a multi way classification where we have 64 classes (the maximum number of cars that are in any image/patch is 64).
* I took the training and test set together and later split it.
* With close to 1 million images, the accuracy achieved was ~55%.
* But if all the images from training and test set is taken it would take approx. 2 days to train the model.
* So,I trained the model by logistic regression using Tensorflow, where I took the image in batches (say, 50).
* With close to 40,000 images, The accuracy achieved was ~48%.

But the methodology mentioned in the paper is able to achieve an accuracy of ~80%.

## How may we increase the accuracy? ( Have to try these out, once I do, I will update the post)

* Instead of inception model, use a different model, like Resception, [Mundhenk et al. 2016](https://gdo-datasci.ucllnl.org/cowc/mundhenk_et_al_eccv_2016.pdf)
* Reserve the Utah region (both training and test) for training purposes as it differs significantly in car density, building architecture, & vegetation patterns from regions in Germany, New Zealand, and Canada, hence provides a rigorous training case.
* Run on the validation set provided by the authors of the paper.

## By the end of the internship, I expect to...

* Get intermediate experience with deep learning frameworks like [Tensorflow](https://www.tensorflow.org/) & [Pytorch](http://pytorch.org/) and machine learning libraries like [scikit-learn](http://scikit-learn.org/stable/).
* Get more familiar with various deep learning approaches.
* Be proficient in skimming through research papers and apply the methodologies to practical projects (Because reading research papers is so damn boring!).
* Build a foundation to become a machine learning engineer after my graduation!

I will update the code on Github as well once I complete the project.

This is me giving the talk :)

![meetup]({{ site.url }}/assets/image4.jpeg)

I gave this talk at the Melbourne MLAI meetup. This is the Meetup [link](https://www.meetup.com/Machine-Learning-AI-Meetup/events/242581813/?gj=co2&rv=co2).

Hope you enjoyed it! :)


