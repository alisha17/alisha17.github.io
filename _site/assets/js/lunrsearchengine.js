
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/about",
    "title": "About Me",
    "body": "I love programming, watching movies, teaching and running. I love eating and trying out new cuisines and restaurants too. I completed my Master of Science (Computer Science) from University of Melbourne. My thesis is on ‘Fake News Detection on Twitter by Evaluating User Credibility’. Previously, I have interned with Silverpond as a Machine Learning Engineer, Fedora as a Software Engineer and Linux as a Software Engineer. I have worked at Move37 as a Software Engineer where I worked on the Natural Language Processing features of the product. I am currently working at CSIRO’s Data61, which is an Australian Commonwealth Research Organization. I am working in the Privacy Enhancing Systems group. I have experience in Python, Javascript, NodeJS, ReactJS, Scala and a bit of Haskell. Don’t hesitate to contact me if you have any questions or you could just maybe drop me a message (via Twitter, LinkedIn or my email) and say hi! "
    }, {
    "id": 2,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           Code Camp - September 2020 edition!                              :               Code camp​ is a 2 - 4 day coding camp for kids aged 5-14 where they code, create and develop their very own app, with. . . :                                                                                                                                                                       Alisha                                17 Nov 2020                                                                                                                                                                                                                                                                                                                  Authentication using Okta API in Node. js                              :               I am currently working on a project which involves implementing authentication using API’s of various identity providers. This is a code example of authentication using. . . :                                                                                                                                                                       Alisha                                03 Feb 2020                                                                                                                                                                                                                                                                                                                              My journey of getting into the Outreachy Program                              :               What is Outreachy?:                                                                                                                                                                       Alisha                                17 Dec 2017                                                                                                                                                                                                                                                                                                                  Performance Comparison between NVIDIA’s GeForce GTX 1080 and Tesla P100 for Deep Learning                              :               Introduction:                                                                                                                                                                       Alisha                                15 Dec 2017                                                                                                                                                                                                                                                                                                                              Parsing Windows event log files (. evtx) using Python                              :               Recently I came across a problem in which I had to convert . evtx files (Windows Event Log files) to a human readable format like XML,. . . :                                                                                                                                                                       Alisha                                25 Nov 2017                                                                                                                                                          All Stories:                                                                                                     Highlights from PyCon Italy              :       Every good thing comes to an end and so PyCon Italy has also ended. This was my first time at Pycon Italy and infact, this was my first time in. . . :                               25 Apr 2018        &lt;/span&gt;                                                                                                                             Extract random images from videos in Python              :       I am working on the automatic logo detection in the sports videos using Deep Learning. For this, i willbe using the Faster-RCNN model. :                                                                               Alisha                29 Dec 2017                                                                                                                                     My journey of getting into the Outreachy Program              :       What is Outreachy?:                                                                               Alisha                17 Dec 2017                                                                                                                                     Performance Comparison between NVIDIA’s GeForce GTX 1080 and Tesla P100 for Deep Learning              :       Introduction:                                                                               Alisha                15 Dec 2017                                                                                                                                     [PyConID Talk] Introduction to Functional Programming in Python              :       What is Functional Programming?:                                                                               Alisha                12 Dec 2017                                                                                                                                     Understanding LDAP terminologies              :       When I started to look into the Fedora’s 389 Directory Server, my first concern was understanding LDAP glossary!:                                                                               Alisha                25 Nov 2017                                               &laquo; Prev       1        2        3      Next &raquo; "
    }, {
    "id": 4,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 6,
    "url": "http://localhost:4000/page3/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 7,
    "url": "http://localhost:4000/codecamp2020/",
    "title": "Code Camp - September 2020 edition!",
    "body": "2020/11/17 - Code camp​ is a 2 - 4 day coding camp for kids aged 5-14 where they code, create and develop their very own app, with help and support from instructors and assistants. This time I participated in the code camp held at Waverley College,Sydney from 29th Sep - 1st Oct. The classes run from 9am to 3. 30pm with a recess from 10. 45 - 11. 15am and a lunch break from 12. 45-1. 30pm. There were four different classes for the kids to choose from:  Spark​ - Spark class is for kids aged 7-12. They learn how to design games (including heroes, coins, swords, lives, different scenes like beach, castle etc. ) using drag and drop code and logic to connect the elements with each other in a level or a scene. All the games are developed on the Code Camp World platform. It involves coding visually which makes it easy to understand the role each function playing their game, hence helping enhance their creativity and cognitive abilities at the same time. The following picture is from the spark class:    Ignite​ - Ignite class is the next level after completing the Spark class. The kids still design and develop games using drag and drop, however it also includes some basic javascript coding. The games are more advanced than thegames designed in the Spark class.     WebBuilders​ - Web builders is for kids aged 8-13. This is a fairly advanced level and is recommended to be done after Spark and Ignite classes. The kids learn how to create asimple website (for eg: portfolio, calculator, tetris game) using HTML, CSS and Javascript. They have full control over what they want to create, so their creativity has no bounds! The following is a picture from Web builders class:     Youtube Creators​ - I wish there was a youtube creators class when I was a kid! With the advent of social media apps like Instagram and Tik Tok and video streaming platforms, creating videos has become an essential skill. This class is very new and was offered for the very first time during these school holidays (Sept’20) and still had a lot of kidsregistered for it!This class is for kids aged 8 -13 and as the name suggests, they learn how to plan, design, shoot and edit their videos including how to cut footage and add music, different video effects and transitions etc.  I mainly assisted in teaching the Spark and Web Builders classes this time. Some observations:  Most of the kids were very happy and really interested in creating games and websites, while some were clearly pushed by their parents and sent to the camp to learn coding.  Most of the kids had already participated in these coding camps in previous terms and were excited to do the next level (Web builders &gt; Ignite &gt; Spark) The kids also spent some time working on their games and websites out of the class, which is very encouraging! (P. S. they can access it using the Code Camp World platform anytime) Although code camp provides laptops to work on, many kids brought their own laptops and were quite good at using it, which means they are already tech savvy! Although code camp markets these camps really well and within diverse communities,  on an average the male to female ratio was 2:1 and there were not a lot of kids  from diverse ethnic and cultural backgrounds. (This might vary on the location and city)And one last picture taken during the recess! (It was a beautiful day. . :) ) "
    }, {
    "id": 8,
    "url": "http://localhost:4000/nodejs-okta/",
    "title": "Authentication using Okta API in Node.js",
    "body": "2020/02/03 - I am currently working on a project which involves implementing authentication using API’s of various identity providers. This is a code example of authentication using Okta in Node. js.  I am using the path /login/okta with POST method.  You can refer to the Okta documentation to login using authentication API here: Okta Authentication API For the request body, we need a username and password.  OKTA_APP_URI is the url of our Okta application.  After authentication via Okta, I am using the profile information in the body of the response and expiry date returned via Okta to create a JWT token. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960router. post('/login/okta', async function(req, res, next) { const username = req. body. username; const password = req. body. password; if (!username || !password) {  res. status(400). json({   message: 'name or password missing - both must be supplied for login'  }); } else {  request. post(OKTA_APP_URI, {   json: {    username: username,    password: password,    options: {     multiOptionalFactorEnroll: true,     warnBeforePasswordExpired: true    }   }  }, (error, resp, body) =&gt; {   if (error) {    console. error(error);   } else {    if (resp. statusCode === 401) {     res. status(401). json({      message: 'Invalid password or user name'     });    } else if (resp. statusCode === 200) {     let userProfile = body['_embedded']['user']['profile'];     let expiry = Date. parse(body['expiresAt']);     let payload = {      iss:  org_name , //can assign from env var      sub:  auth. api , //can assign from env var      jti: uuid4(),      exp: expiry,      claims: {       firstName: userProfile. firstName,       lastName: userProfile. lastName,       username: userProfile. login      }     };     let token = jwt. sign(payload, jwtOptions. secretOrKey, {      algorithm: jwtOptions. algorithm     });     res. status(200). json({      message: 'Login was successful',       token : token     });    } else {     res. json({      message: 'Please refer to Okta error codes and description:\\' +        '\ https://developer. okta. com/docs/reference/error-codes/#example-errors-listed-by-http-return-code\\ '     })    }   }  }); }});Hope this helps someone. If you have any questions, feel free to comment below! "
    }, {
    "id": 9,
    "url": "http://localhost:4000/pycon-italy/",
    "title": "Highlights from PyCon Italy",
    "body": "2018/04/25 - Every good thing comes to an end and so PyCon Italy has also ended. This was my first time at Pycon Italy and infact, this was my first time in Italy. I gave a talk on how FOSS has helped me become a better programmer and then I demonstrated some of the work that I did as a part of the Outreachy internship. The venue was Grand Hotel Mediterraneo, just 20 minutes walk from the city centre of Florence (how convenient!) and the conference was from 19th April-22nd April. The talks and tutorials were in both Italian and English. The first day was the beginners workshop day. I wasn’t able to attend that as my flight landed at night of this day. The talks and tutorials started from the second day, i. e. the 20th April. Since there were multiple tracks, I couldn’t attend all of the talks. But I attended some of the very interesting talks. I would try to briefly describe some of the talks: Day1:: Keynote: Don’t try to look smart, be smart by Flavio Percoco: Flavio reflected upon some of his experiences he has gone through his career and advises how others should tackle some of these situations in a better way. Keynote: Can we make the light bulb want to change by Mikey Ariel: Mikey discussed about how going out of your comfort zone can help in growing personally and professionally. Talk: The practice of TDD: Tips and tricks by Antonio Cuni: Antonio discussed about Test driven development in software engineering projects with some examples from his real projects. He also demonstrated some popular testing tools, with main focus on pytest. Talk: Unveiling the potential of graph databases with Python and Neo4j by Fabio Lamanna: Fabio in his talk showed some tips to set up in the right way the data using Pandas, in order to proper model and import them into Neo4j. Neo4j has become a popular graph database in recent years because of its capacity to model relations among data, its high availability and its easy, fast and clean query language Cypher. Talk: Everyday security issues and how to avoid them by Christian Heimes: Christian described about secure software design and illustrates various attack vectors. It included topics like threat analysis, deployment, parsing, authentication, TLS/SSL, crypto, and user interaction, with some real life examples from his daily work. Day 2:: Talk: How to use web sockets in Python by Anton Caceres: Anton showcased how to run Web Sockets with Python web-apps, starting from situations that can make a good use of it, and followed by an implementation with most practical frameworks: Tornado and Django Channels. Talk: Working for FOSS can make you a better programmer: Insights into my Outreachy internship with Fedora: I shared about how I started working for FOSS organisations and how it helped me become a better programmer. I also shared some of the work I did for Fedora as part of my Outreachy internship and elaborated on the skills I gained while working for it (both technical and soft skills). Talk: Image generation with Tensorflow by By Cenk Bircanoğlu: Cenk discussed about GANs (Generative Adversarial Networks) and the implementation details on Tensorflow, which was divided into 2 parts. One is called generator and other is called discriminator. He also elaborated upon the differences between the discriminator and generator. Day 3:: Talk: Location, location, location: Data Visualisation and Analysis of Geospatial data in Python by Michele Ferretti: Michele discussed about the popular format used for geospatial data (. shp) and coordinate reference formats and how analysis and visualization can be done for it using geopandas in Python. Talk: What’s going on there? Understanding cities with location data by Gianni Barlacchi: Gianni’s talk was like an extension to the previous talk by Michele Ferretti. He discussed how we can using Python collect and aggregate geo-located data and build machine learning models to predict spatiotemporal activities. For example, an unusual activity in a local area at a specific time can be predicted by analyzing the text from geo-located tweets. Talk: A primer on the Ethereum Blockchain and Smart Contracts using Python and Serpent by Stefano Fioravanzo: Stefano reviewed the basic concepts behind Blockchain, starting from its very first implementation: The Bitcoin Blockchain (strengths and limitations). He also elaborated on Python tools that we need to use to interact with the Ethereum blockchain and develop Smart Contracts. The audience learnt how to write a simple Smart Contract, test it and deploy it to the local running blockchain. Talk: Serverless SQL queries from Python with AWS Athena…or power to Data Scientists! By Daniela Scardi: Daniela explained how Athena, a serverless sql-like query service provided by Amazon’s AWS, combined with a Python library called PyAthena, made it possible to store and query as much data as needed with low costs, high performances and in a Pythonesque way. All the talks were a mix of web, data and community related. Moreover, the best part of conferences is meeting new people who have similar interests as yours. I definitely met a lot of interesting people and it was an enriching experience for me. "
    }, {
    "id": 10,
    "url": "http://localhost:4000/extractimagesfromvideos/",
    "title": "Extract random images from videos in Python",
    "body": "2017/12/29 - I am working on the automatic logo detection in the sports videos using Deep Learning. For this, i willbe using the Faster-RCNN model. To train the model with the annotations in the images, I required random images from the selected videos. Following is the script (this is in python2; for python3, it should just be a matter of using parentheses with print) that I used for extracting images from videos. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import skvideo. iofrom matplotlib import pyplot as pltimport random# Return 'num_images' no. of random imagesdef random_items(iterator, num_images=1):  selected_items = [None] * num_images  for item_index, item in enumerate(iterator):    for selected_item_index in xrange(num_images):      if not random. randint(0, item_index):        selected_items[selected_item_index] = item  return selected_items# Read the video, extract images and save them to a directorydef extract_images(video_path, num_images, save_to_path):  # Use vreader as it loads the video frame-by-frame  # If it is a large video, using vread() may exhaust the memory  videogen = skvideo. io. vreader(video_path)  random_set = random_items(videogen, num_images)  count = 0  for frame in random_set:    directory =  {0}/image{1}. png . format(save_to_path, count)    plt. imsave(directory, frame)    # if you instead want to just show the images in a notebook    # instead of saving, use imshow()    # plt. imshow(frame, interpolation='nearest')    plt. show()    count += 1if __name__ == '__main__':  import argparse  parser = argparse. ArgumentParser()  parser. add_argument('--video-path', required=True)  parser. add_argument('--num-images', required=True)  parser. add_argument('--save-to-path', required=True)  args = parser. parse_args()  extract_images(args. video_path, int(args. num_images), args. save_to_path)Run the above code using the following command (I wanted 250 random images from this video): 12python extract_images_from_videos. py --video-path= /home/alisha/AFL 2017 Season Highlights-0O3rHhzO9VQ. mkv  --num-images=250 --save-to-path= /home/alisha/test_folder I hope this helps! :) "
    }, {
    "id": 11,
    "url": "http://localhost:4000/outreachy_journey/",
    "title": "My journey of getting into the Outreachy Program",
    "body": "2017/12/17 - What is Outreachy?: Outreachy provides three-month internships for people from groups traditionally underrepresented in tech. Interns are paid a stipend of $5,500 and have a $500 travel stipend available to them. Interns work remotely with mentors from Free and Open Source Software (FOSS) communities on projects ranging from programming, user experience, documentation, illustration and graphical design, to data science. Interns often find employment after their internship with Outreachy sponsors or in jobs that use the FOSS skills they learned during their internship. Outreachy internships are open internationally to women (cis and trans), trans men, and genderqueer people. Internships are also open to sresidents and nationals of the United States of any gender who are Black/African American, Hispanic/Latin@, Native American/American Indian, Alaska Native, Native Hawaiian, or Pacific Islander. How I ended up being an Outreachy Intern at Fedora?: I first heard of Outreachy through a friend in 2015. But at that time, I had just completed my undergrad and was not confident of myself AT ALL, which is really justifiable, since you cannot think of working for top-notch organizations/communities like Mozilla, Fedora, Linux, Wikimedia and many more. . Getting started with open source: However, I was really intrigued with the idea of Free and Open Source Software (FOSS). Hence, I decided to make some contributions towards it. Mozilla is an organization that everyone must have heard of since childhood. Atleast I am using Firefox from the time I first started using computers. Fortunately, I have a friend who was already a contributor in Mozilla automation and tooling projects. She introduced me to a Senior Engineer working at Mozilla. He mentored me and helped me in making my first contribution. In a span of one year, I contributed to Bedrock, Firefox, Treeherder and Taskcluster and have around 35 merged PRs into the codebases. Outreachy round 14: Disappointments: I decided to apply for Outreachy round 14 (June-Aug’17); for which the applications open in February. There were some many awesome organisations and projects. I was already familiar with how Mozilla’s bug tracking system works (using Bugzilla), how to open PRs and how the reviews work etc. I chose 2-3 projects which I found interesting. I made contributions to all of them, butultimately the project which interested me the most was Rust Web Assembly Showcase. The mentor of the project was Brian Anderson (co-creator of Rust). The task of the project was to create a web application in Rust and compile it to Web Assembly. I started fixing some Rust bugs and making small Rust applications all compiled to Web Assembly. It was so much fun! Brian shortlisted me as the Outreachy intern for his project. But then this happened…. . A week before the selected Outreachy interns were to be announced, I received a mail from the organizers informing me that I was not eligible for the internship since I did not have full 3 months off from the university, and the Outreachy eligibility criteria clearly states this. Though, I had like full 2 months off, but the academic calender did not explicitly asserted this. Me and Brian tried to convince them, but probably they were right as they did not want the intern’s studies to suffer. Brian was disappointed too (since I had already started working on the project) and I was very disheartened, but that did not deter me from working harder and learning Rust in the process. Brian, being an awesome Rust community member, still mentored me all through the summer like he would mentor an intern and I ended up doing two Rust projects: Tic-Tac-Toe and Testrunner. [Thanks Brian!]. We had weekly Hangouts and IRC meetings, code reviews, bug fixes and it was a great learning experience. I even completed the Rust Libz-Blitz contest and won free tickets to Rust Fest Switzerland, but I wasn’t able to go anyway (That’s a story for another day! :-p) Outreachy Round 15: Finally!: I was really excited for Outreachy Round 15 (Dec’17-March’18) and was determined to apply for it. There was no Rust project this time but I found another interesting project to apply for which was Fedora’s Developing administrative tools for 389 Directory Server and the mentor was William Brown (Software Engineer, Red Hat AU). Fedora is a Unix-like operating system based on the Linux kernel, developed by the community-supported Fedora Project and sponsored by the Red Hat company and the 389 Directory Server is an enterprise-class Open Source LDAP server for Linux. It handles many of the largest LDAP deployments in the world. The basic task of this project was to improve the Directory Server’s python command line tools. Why I found this project interesting?   LDAP - Anyone who has any acquaintance with LDAP will understand my bittersweet love for it. It has a very steep learning curve but is interesting as hell. Its structure and schema is nothing like your conventional databases. Moreover, there are not much learning resources online, so you have to explore and read the codebase to understand deeply. So, what can be the best way of learning a new thing than actually working on it, because no amount of learning from online resources can beat practical experience with the help of an awesome mentor!     Python - I just love Python. I already program in Python and more the experience, the better it is.     Community - I have had experiences with some open-source communities which were not good at all. So, community matters a lot for me. You don’t want to feel scared while asking things from the community.  I started contributing to this project and it was so exciting! Even in the process of fixing some bugs which was essential for submitting the application for Outreachy, I learnt a great deal (setting up the Directory Server, setting up Apache Directory Studio, LDAP concepts etc. ). I got selected as an Outreachy intern for this project and now I am working on it! :) William is an amazing mentor as well as an amazing community member. He is always so supportive and provides guidance and explains each concept very thoroughly with patience. I can not imagine working without his direction. [Thanks William!] The journey wasn’t easy but was worth it. Even the little bug fixing and contributions for applying for the internship teaches you skills such as time management, especially if you are a student like me. Some tips for Outreachy aspirants:: CHECK THE ELIGIBILITY CONDITIONS, I REPEAT, CHECK THE ELIGIBILITY CONDITIONS!: You don’t want to get disappointed only to be notified later that you are not eligible, after putting in a lot of time and effort and as a result shattering all your hopes! I was really paranoid about the eligibility when I was applying this time. I checked maybe 50 times :P CHOOSE PROJECT THAT INTERESTS YOU: You don’t wanna do the project just for the sake of getting selected as an intern. Remember, you will be doing this project for 3 months full-time. So, it should actually excite you! GET STARTED WITH VERSION CONTROL SYSTEMS LIKE GITHUB: This is very essential as almost all open source repositories use some king of version control systems like github or their inhouse systems like Fedora uses Pagure, but the essence is the same. If you know how to drive a car, you can drive any car. So, maybe start with using Github, learn about the basic commands (push, pull, commit etc. ), push your local projects, play with using git from CLI etc. START CONTRIBUTING AS EARLY AS POSSIBLE: I was already an open source contributor from past 6 months when I applied for the first time for Outreachy and I was familiar with how things like Pull Requests, Patch Reviews, Bug Filling, Bug fixing etc. worked. If you start with these things during the Outreachy application period, you will spend more time understanding these and subsequently, you will get less time to work on the actual project. COMMUNICATION MEDIUMS - IRC, SLACK: Probably IRC is the most common open source communication medium. Communities like Fedora, Mozilla, Openstack use IRC. It facilitates communication in the form of text and is based on client-server communication. Read about how IRC works and setup a client for it. I use Hexchat for IRC and it works like a breeze. Slack is pretty popular these days and getting started with it is as easy as creating an account and start talking. You can also download the Slack iOS or Android app to always remain updated. RESPECT YOUR MENTORS: I consider myself lucky as I have always had amazing mentors. But remember, they are also human beings. By mentoring you, they are putting double the efforts (as most of them are full-time employees as well). So:  Respect their time, do not bug them too much.  Talk to them politely (mails/slack/IRC). Use the magic words, ‘sorry’, ‘please’, ‘thankyou’.  Be honest with them. If you don’t know something, ask them. They are there to help you.  Be in touch with them and talk about your progress regularly. ASK QUESTIONS, A LOT!: The more you ask, the more things become clearer. Don’t be afraid to ask. The mentors and the community will help you. Most of the mentors are really passionate about their projects and will genuinely want you to learn more and more. TIME MANAGEMENT: This one is probably useful during the application process. If you are a student like me, you will have to juggle studies and exams with bug fixes/understanding the projects etc. This was my routine during the application period: Morning till evening studying and attending classes at the university, then I used to come home around 6. 30, have my meal and sleep for like 1 hour. Then from 8 till 1 am, I used to work on the project. I am quite focussed at nights :) Any Questions?: If you have any questions about the Outreachy program, application process, Mozilla, Fedora, github, IRC etc. etc. , don’t hesitate to drop me a mail or connect with me on Twitter/LinkedIn! Thanks! :) "
    }, {
    "id": 12,
    "url": "http://localhost:4000/benchmarks/",
    "title": "Performance Comparison between NVIDIA’s GeForce GTX 1080 and Tesla P100 for Deep Learning",
    "body": "2017/12/15 - Introduction: This post aims at comparing two different pieces of hardware that are often used for Deep Learning tasks. The first is a GTX 1080 Ti GPU, a gaming device. The second is a Tesla P100 GPU, a high-end device devised for data centers which provides high-performance computing for Deep Learning. Hardware: The hardware specifications of both the devices are:           GeForce GTX® 1080 Ti   Tesla® P100-SMX2         CUDA Cores   3,584   3,584       Floating-point Performance (TFLOPS)   11. 3   10. 6       Memory   11 GB (GDDR5X)   16 GB (HBM2)       Max Power Consumption   250 W   300 W       Launch price (USD)   $699   $9,428   Tesla P100 has more memory than GTX 1080 Ti. Also, high-bandwidth HBM2 memory is significantly faster than GDDR5X. The direct CPU-to-GPU NVLink connectivity on P100 enables 5X faster transfers than standard PCI-E. However, the cost of P100 is almost 15X more than the 1080 Ti. Software: We have used the following components for the software:  NVIDIA CUDA Toolkit: 8. 0 NVIDIA cuDNN: 5. 1 Python: v3. 6. 3 NumPy: v1. 13. 3 TensorFlow: v1. 4 NVIDIA graphics driver: v384. 81Dataset: The Cars Overhead with Context (COWC) dataset is a large, high quality set of annotated cars from overhead imagery. The data consists of ~33,000 unique cars from six different image locales: Toronto Canada, Selwyn New Zealand, Potsdam and Vaihingen Germany, Columbus and Utah United States. The dataset is described in detail by Mundhenk et al, 2016. The Columbus and Vaihingen datasets are in grayscale. The remaining datasets are 3-band RGB images. Data is collected via aerial platforms, but at a view angle such that it resembles satellite imagery. We chose this dataset as we were already working with it for a project ‘Counting the number of cars in satellite imagery using Deep Learning’. Datasets like MNIST do not aid much in the evaluation of the hardware configurations, since it is a small dataset. Therefore, it is much desirable to use larger and more complex datasets. Model: The Inception v4 model is known to perform very well on the ImageNet challenge. It has 95. 2% Top-5 accuracy. However, it did not perform well on our classes of interest. So we fine-tuned this model to adapt for our classes (this approach is also called ‘Transfer Learning’) and named it as ‘Pondception’. Benchmarks: In order to compare the performance of both the hardware architectures, we used four benchmarks:  We trained the Pondception classification network model till 2000 steps for the dataset on the CPU and both the hardware configurations.  We used the maximum batch size that the memory of both the hardware configurations can fit and train the model.  We monitored the amount of energy consumed and the temperature of both the hardware configurations during the training of the model.  We ran some popular convolutional neural network models on both the hardware configurations on synthetic data to avoid potential disk I/O as an overhead. Results: Time taken during training: For a batch size of 32 and 2000 training steps, the total time taken to train the model on the CPU, P100 and 1080 Ti was:           GTX 1080 Ti   Tesla P100   CPU         Total time taken (in min)   67   51   240       % of time taken   100%   76%   400%   We can see that the GPU’s are significantly faster than the CPU, with about 4X speedup. Regarding the comparison between both the GPU’s, the P100 outperforms the 1080 Ti, though there is only 1. 3X speedup, i. e. the time taken for training is reduced by approximately 20%. Evaluation Metrics and Validation Loss comparison: Since the P100 has a larger memory size (i. e. 5 GB more than the 1080 Ti), it is able to fit a larger batch size for the given dataset. While the largest batch size for 1080 Ti is 32, the largest batch size for the P100 is 85. Training with these batch sizes and taking 2000 training steps gives the following results for the evaluation metrics and the loss in validation.  As we can visualize from the bar chart, there is not much difference in the metrics even though we had taken a larger batch size for the P100. In fact, the accuracy and the other metrics decrease by around 2% in the case of P100. So, we can’t conclude that if we have a larger memory in a GPU and take a larger batch size, it will give better validation accuracy. Moreover, the time taken for training with a larger batch also increases significantly. In the case of P100, while the time taken for training with 2000 steps and the batch size as 32 was 51 minutes, the time taken for training with same number of steps but with the batch size as 85, was 120 minutes (almost double!).  If we visualize the plot for validation loss in the model for both the GPU’s for 2000 steps, we can see that the validation loss is decreasing more at every subsequent checkpoint in the case of P100. It might have decreased more and converged earlier in case of P100, had we trained for more number of steps. Power Consumption and Temperature analysis: We recorded the power consumption and the temperature of the 1080 Ti and P100, for 5000 points at equal time intervals during the training of the model. Following is the plot for the power consumption by 1080 Ti and P100 during training of the model: Following is the plot for the temperature of 1080 Ti and P100 during training of the model: As we can infer from the plots, P100 definitely beats 1080 Ti in terms of power consumption and the temperature. For the temperature, it is natural since 1080 Ti GPU’s are installed in our office at room temperature and do not have any special cooling system besides the fans located in the device. Since P100 runs at a lower temperature as compared to the 1080 Ti, it might have special cooling systems or better heat management mechanisms . Image classification models performance: In this section, we use InceptionV3, ResNet-50, VGG16, and ResNet-152 models on synthetic data to compare the performance of P100 and 1080 Ti. Speedup over CPUCompared to the CPUs, GPUs provide huge performance speedups during deep learning training. This is analyzed from the following bar chart. The ResNet-50 model is trained with a batch size of 64.  Speedup with multi-GPUsTraining on double GPUs enhanced the performance significantly, be it P100 or 1080 Ti. However, the P100 was not much faster than the 1080 Ti (with double GPUs). There was only slight improvement, as clear from the line plot below.  Half-Precision (FP16) PerformanceAccording to the official documentation, P100 is designed for high-performance double-precision floats (FP64) which is used in many HPC applications such as quantum chemistry and numerical simulation, since there are 1792 double-precision CUDA cores, which is half the number of single-precision (FP32) CUDA cores. Even with the GPUs like the 1080 Ti or the Titan X, we can compute with half-precision floats (FP16), however the performance will be slower than single-precision floats (FP32). The P100 also supports FP16 calculation which speeds up deep learning. Following is a comparison of FP16 and FP32 performances on the P100. There is around 13% speedup on average in this case.  Memory BottleneckGPU memory will never be too much for large-scale deep learning training. Sometimes the memory will be a bottleneck for training efficiency. Larger mini-batches are more efficient to compute and lead to better convergence in fewer epochs , but at the same time they also require more GPU memory. P100 has 5GB more memory than 1080 Ti, which enables larger batch size in deep learning. For example, if we use a batch size of 64, the 1080 Ti will run out of memory, however the P100 will still work. This is demonstrated in the following bar chart.  One possible approach to avoid this is by applying half-precision computing because storing FP16 data compared to the higher FP32 or FP64 reduces memory usage, which enables us to use larger batch size or train larger networks. For example, if we use FP16 with a batch size of 64 on ResNet-50 model in 1080 Ti, then the out-of-memory problem will be solved. This is demonstrated in the following bar chart.  Conclusions: We compared two different GPUs by running a couple of Deep Learning benchmarks. These devices are GeForce GTX 1080 and Tesla P100. After looking at the results, we can argue that the P100 is probably not worth the cost (which is 15X more than the 1080 Ti), while the performance is generally around 15% better. However, as already discussed in previous section, the larger memory size of P100 would enable to either work with larger networks or with larger batches. Larger batches could lead to better convergence of the gradient descent process, enabling us to train a successful model in a smaller number of epochs. Moreover, P100 might last longer given that it is a high-end device specially devised for datacenters and runs on a lower temperature and is much cooler as compared to the 1080 Ti. "
    }, {
    "id": 13,
    "url": "http://localhost:4000/funcprog/",
    "title": "[PyConID Talk] Introduction to Functional Programming in Python",
    "body": "2017/12/12 - What is Functional Programming?Programming paradigm: The programming paradigms can be roughly divided into four categories, namely the imperative programming, where you specify do this, do that, then do this. Python is an imperative language. The second category is object oriented programming, where you model your data in the form of classes, objects and methods. Java, C++ and even Python support OOP. The third category is the logic programming paradigm, where you define some facts and relations and then query data on the basis of them. Prolog and Lisp is an example of this. The fourth category is our functional programming paradigm, where ‘function’ is the keyword to remember. Everything is done using functions. Way of approaching problems: It is a way of approaching problems, a different way of thinking of the tasks at hand. If you have always programmed in Java, C#, Python etc. , you might find it hard to write programs initially using functional programming. This is what at least happened with me! Functions, Functions everywhere: Everything is expressed in the form of ‘functions’. Function is anything that takes an input, performs a specific task and gives out output and nothing else!! Let’s see a simple example of “hello world”: 123str1 = 'hello'str2 = 'world'print str1+' '+str212def hello():   return 'hello world'The first code snippet just concatenates and prints two strings, but the second code snippet returns thestring from a function. Hence, the second one is clearly functional programming whereas first one is not. Features of functional ProgrammingPure Functions: Pure functions are functions without ‘side effects’. It takes an input and only input and computes the output. Side effect is anything other than just taking an input, processing it and returning an output, which includes any interaction with the outside world. In brief, it means taking something from the outside world and involving it in someway with what the function does. Example- A function might take a global variable which means that it does not depends on only the input of the function. Printing something on the terminal or reading data from keyboard, mouse etc. , where mouse and keyboard are the objects of outside world is also a side effect. So, you want your function to take an input and only input and compute the output and return that. That’s it! One of the key parts of functional programming is thinking as ‘purely’ as possible. Immutability: Avoid mutability, i. e. never change the data. Consider the example below, In this destructive update example, we can see that in imperative languages, the natural way to insert a value into a table is to modify the table in place, ‘which is a side effect’, because it is modifying the input. But in functional languages, you create a new version of the table while the old version is still there, which can be used for purposes of comparisons or implementing undo. If you update the data in place and suppose you have the same data at other places as well, i. e. somewhere in other functions, this will produce the much dreaded BUGS! Oh no! So the advantage of immutability is parallel programming, since the data remains the same always, people in teams at different geographical locations can access the data without worrying about ‘Oh, this might be changed now, i need to get the latest commit of the project!’. Some people even think programming with dozen of cores that the CPU’s will have in future is the killer application of functional programming! Recursion: Use recursion instead of loops and iterations since pure functional programming languages have NO LOOPS! Yes, no for loop, no while loop. But why? Pure functional programming means programming without side effects. Which means if you write a loop, the body of the loop can’t produce side effects. Thus, if you want your loop to do something, it has to reuse the result of the previous iteration and produce something for the next iteration. This does not have a huge advantage over directly writing a recursive function for the loop. Tail Recursion Optimization: You must have a question, if the recursion is done a large number of times, it will exhaust the space. The functional programming languages optimise recursion using TRO. Consider this example, There’s this function a(), which is returning b(). However, b() is just calling c() and will return the value of c() to a(). So technically, b() is just doing the work of a mediator between a() and c(). So the stack frames for a() and c() will be made which will hold the local variables and address parameters for both the functions, but no stack frame will be made for b() because it is just calling c() and returning the value to a(). This is called last call optimisation. Tail call optimisation/ Tail recursion optimisation is a special case of last call optimisation, where the function calls itself repeatedly, therefore replacing its stack frame and not creating new ones. So even if you call a function million number of times, it will never exhaust the stack space, since it is ‘replacing’ itself each time the function is called. So, the useful part is, because only the final result of each recursive call is needed, earlier calls don’t need to be kept on the stack. Instead of “calling itself” the function does something closer to “replacing” itself, which ends up pretty much looking like an iterative loop. This is a pretty straightforward optimization that almost all functional programming compilers generally provide. Lazy Evaluation: Imperative programming languages follow eager evaluation, i. e. expression is evaluated as soon as it is bound to a variable. It forces the evaluation of expressions that might not be needed at run time. But lazy evaluation means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations. In consequence, arguments are not evaluated before they are passed to a function, but only when their values are actually used. Fo example, consider this Haskell code snippet which computes the length of the list 12len []   = 0       -- Length of empty list is 0len (x:xs) = 1 + len xs  -- Recursively call len functionx and xs both are variable where x is the head of the list and xs is the tail of the list. You can see that we have neither given any value of x nor using it anywhere in the logic, but the program will merely give the warning but compile as expected, because Haskell is a lazily evaluated language and it will not evaluate the value of x until it really needs it.  Partial application: Partial application meand freezing some of the arguments of a function Consider this Haskell code snippet, 1234add :: Int -&gt; Int -&gt; Int​add x y = x + y​addOne = add 1​We are defining addOne with already prefixed argument of add as 1. So if we need to compute the sum of 3+1, we would just do 1addOne 3​We can consider this as: 12&gt; addOne 3&gt; (add 1) 3Functions as ‘first class citizens’: We can assign the functions to variables, store them in data structures, pass them as arguments to other functions, and even return them as values from other functions. How is functional programming done in Python?Immutable Data types (String/NamedTuples/Frozenset): Namedtuples: Tuple uses numerical indices to access its members, whereas namedtuple assigns name as well as numerical index to its members, hence preventing the errors caused by explicitly remembering the index as in tuples. Each namedtuple is represented by its own class. The arguments passed are name of the class and a string containing its elements. 1234567891011121314151617from collections import namedtuple# Arguments are name of the class and a string containing the names of the elementsPerson = namedtuple('Person', 'name gender')alisha = Person(name = 'alisha', gender = 'f')# Fields by nameprint ( Fields accessed by name are: )print ( Name is %s and gender is %s.  %(alisha. name, alisha. gender))# Fields by indexprint ( Fields accessed by index are: )print ( Name is %s and gender is %s.  %(alisha[0], alisha[1]))# Try mutating the elements (will get error)alisha. name =  somerandomname Frozenset: frozenset is an immutable version of the Python set. Once created, it cannot be modified. Due to this reason, they are used as dictionary keys as well. It can be empty or can take a single parameter which is an iterable (lists, tuples, dictionary etc. ) 123456789101112food = ['cake', 'burger', 'pizza']fSet = frozenset(food)print (fSet)# Empty frozensetprint (frozenset())# Try adding a new element: errorfSet. add('chocolate')# Try removing a new element: errorfSet. remove('cake')Functions as ‘First Class Objects’: Python’s functions are first-class objects. 1234567891011121314151617181920212223242526272829303132333435def multiply2(a):  return a*2# Function assigned to variablevar_multiply = multiply2print (var_multiply(2))# Function store in data structure (list here)test_list = [multiply2, 7, 8]print (test_list[0](3))# Loop over list as with normal variablesfor i in test_list:  print (i)# Function passed as argument to other functionsdef add(multiply2, b):  a = multiply2(3)  return (a+b)add(multiply2, 3)# Return a function from another functiondef greater(a, b):  def yes_greater():    return ( Oh yeah I am the bigger one! :) )  def no_greater():    return ( Oh no I am the smaller one! :( )  if a &gt; b:    return yes_greater  else:    return no_greatergreater(5, 2)()Higher Order Functions: Higher order functions take in other functions as the argument or can also return a function. map, filter and reduce are perhaps the most common higher order functions found in almost allprogramming languages.  map(): Map takes a function and a collection of items. It makes a new, empty collection, runs the function on each item in the original collection and inserts each return value into the new collection. It returns the new collection. 1234567def multiply2(a):  return (a*2)test_list = [3,5,6,7,8,9,11,12]# Multiply every element of list by 2return_list = list(map(multiply2, test_list))filter(): Filter takes a function and a collection of items. It filters out all the elements of the collection for which the function returns true. 12345678def greater_elem(a):  if a &gt; 10:    return True  else:    return False# Filter if elements are greater than 10return_list = list(filter(greater_elem, test_list))In this example we call the greater_elem() function on every element of the list and return the elementswhich are True for the function. reduce(): Reduce takes a function and a sequence and applies the function continually on the sequence and returns a single value. 1reduce(lambda x,y: x*y, [47,11,42,13])In this example, we are calculating the product of all elements in the list. So the evaluation orderworks like: 1(((47 * 11) * 42) * 13)P. S. reduce() is a part of functools module, so call it as functools. reduce() or import reduce fromfunctools first. Lambda construct: The lambda helps define the functions in a one-line fashion. In fact, the lambda keyword is pretty prominent in functional programming (and not just Python), and has its roots in Lambda Calculus – one of the ‘ancestors’ of functional programming. Functions initialized with lambda can also be called anonymous functions. We aren’t really giving it a name, just defining it on-the-go and passing it as an argument. 1234test_list = [3,5,6,7,8,9,0]# Multiply every element of list by 2return_list = list(map(lambda x: x*2, test_list)) # Define the multiply by 2 function using lambdaList Comprehensions: They are faster than map. A list comprehension can be interpreted as a simple binding because there are no more mutations or reassignments. List comprehensions are directly inspired by Haskell list comprehensions. They are not lazily evaluated though. 1[x * 2 for x in test_list]The same function of multiplying an element by 2, we are defining using list comprehensions instead of lambda as in previous section. Iterators and Generators: Iterators:  Iterators represent a stream of data which returns one element at a time (thus following lazy evaluation).  It must support a next() method, which returns the next element of the stream and return StopIteration exception if there is no next element.  Lists and dictionaries both support iteration.  Iteratora can be materialized it using list and tuple.  Sequence unpacking can be done if number of elements is known.  Files also support iteration by calling the readline() method until there are no more lines in the file. readLine() is lazily evaluated. 12345678910111213141516171819202122list1 = [2,4,7]# iter() takes an iterable and gives one element at a timea = iter(list1)print (a. __next__())print (a. __next__())print (a. __next__())# print (a. __next__()) -will give StopIteration exception# Materialize the iterator using lists and tupleslist2 = [3,7,8,3,8]l = list(list2)t = tuple(list2)print (t)print (l)# Unpacking the iteratorlist3 = [7,8,4]x = iter(list3)(a,b,c) = xprint (a,b,c)Generators:  Generators returns iterator that returns a stream of values.  Normal functions vs generators: When a function reaches the return statement, local variables are destroyed and the value is returned to the caller. A later call to the same function creates a new private namespace and a fresh set of local variables, whereas in a generator function, the local variables aren’t thrown away on exiting a function and we can later resume the function where it was left off. Hence, they can be thought of as ‘resumable functions’.  Any function containing a yield keyword is a generator function.  When we call a generator function, it doesn’t return a single value; instead it returns a generator object that supports the iterator protocol.  On executing the yield expression, the generator outputs the value of i (see in the snippet below), similar to a return statement. On reaching a yield the generator’s state of execution is suspended and local variables are preserved. On the next call to the generator’s next() method, the function will resume executing. ¶123456789101112test_list = [2,3,5,8,8]def yield_elems(test_list):  for i in test_list:    yield i# Return a generatora = yield_elems(test_list)print (type(a)) # Generator objectprint(a. __next__()) # 2print(a. __next__()) # 3Generator Expressions: Generator expressions return an iterator and are lazily evaluated unlike list comprehensions which return a list and are eagerly evaluated. Generator Expressions are written in ‘()’ round brackets whereas list comprehensions are written in ‘[]’ brackets. 12345a = (x for x in [1,2,3,4,5] if x&gt;2)a. __next__() # 3a. __next__() # 4a. __next__() # 5Module ‘itertools’: When we are discussing about iterators in such great depth, we definitely need functions to manipulate the iterators. Itertools has number of iterators and functions to combine several iterators. ‘itertools’ has:  Functions that create a new iterator based on an existing iterator Functions for treating an iterator’s elements as function arguments Functions for selecting portions of an iterator’s output Functions for grouping an iterator’s output. I recommend running these examples in the Python notebook here 123456from itertools import *# takes an arbitrary number of iterables as input, and returns all the elements of the first iterator,# then all the elements of the second, and so on, until all of the iterables have been exhausted. list(chain([1,3,4,5], ['a','b','c']))1234# cycle() repeats the elements infintely, creates new iterators, will have to break out of loop. for i in cycle([2,3,4,7,7]):  print (i)1234# islice() returns a stream that’s a slice of the iterator. With a single stop argument,# it will return the first stop elements. list(islice([4,6,7,3], 1, 3, 2))12345list(combinations([1, 2, 3, 4, 5], 2)) # gives combination of 2 elements in a tuplelist(combinations([1, 2, 3, 4, 5], 3)) # gives combination of 3 elements in a tuplelist(permutations([1, 2, 3, 4, 5], 2)) # gives permutation of 2 elements in a tuplelist(takewhile(lambda x: x&lt;5, [1,4,6,4,1]))list(dropwhile(lambda x: x &lt; 10, [1, 4, 6, 7, 11, 34, 66, 100, 1]))The official documentation is pretty good: itertools. I recommend checking this out. Partial Application: Partial Application is not automatically done in Python. However, the functools module provides thefunction partial() for the same. 12345def sweet(choice1, choice2, choice3):  print( The food I like is %s, %s, %s %(choice1, choice2, choice3))order_sweet = partial(sweet, choice3='ice cream')order_sweet('muffin', 'pancake')In this example, if I am gonna eat a sweet dish I am always selecting an ice cream no matter what, so I freeze the argument ‘ice cream’ and store the function sweet() to order_sweet with the argument choice3 as ‘ice cream’. Recursion: We know how to do recursion in Python. Isn’t? However be careful, you cannot do recursion for a large number as Python is not tail recursive optimized. What are the disadvantages of Functional Programming in Python? No tail recursion optimization It’s impossible to create immutable variables everytime.  It is impossible to seperate pure and non-pure functions.  No pattern matching.  No automatic partial application. Inspite of these disadvantages, it is important for a programmer to make clever use of different programmingparadigms according to the use case and it is good to know various features. Interested in learning more about functional language Haskell?? Check out this: Learn You A Haskell This is the Python notebook link for these examples: Examples. These are the slides: presentation. If you have any doubts regarding this, ping me on Twitter, LinkedIn or comment below in this post. I will getback to you asap! Thanks for reading :) "
    }, {
    "id": 14,
    "url": "http://localhost:4000/ldapconcepts/",
    "title": "Understanding LDAP terminologies",
    "body": "2017/11/25 - When I started to look into the Fedora’s 389 Directory Server, my first concern was understanding LDAP glossary! I did a project of Single Sign-On and Password Authentication using LDAP as the database during my internship in the last year of undergraduation, 2+ years back (time literally flies!), but to be honest, I didn’t really understand much at that time. (It’s better to get started with LDAP using Apache Directory Studio, it becomes easier to visualise things. ) What is DN?: Consider: cn=Alisha, ou=People, dc=example, dc=google, dc=com This whole string is a DN (Distinguished Name). It is a series of comma-separated key/value pairs used to identify entries uniquely in the directory hierarchy. The DN is actually the entry’s fully qualified name, i. e. it uniquely identifies an entry in the directory. DN should be read from right to left. The rightmost component is the root of the tree and the leftmost component is the leaf or the node you want to reach. What is RDN (Relative Distinguished Name)?: Consider: uid=alisha, ou=People, dc=example, dc=com  uid=alisha and ou=People are RDN for dc=example, dc= comConsider: cn=maths, dc=example, dc=com  cn=maths is RDN for dc=example, dc=comHence, RDN is how you name a ‘singlular’ object, whereas DN is the fully qualified path to an entry. Generally according to the convention, uid=&lt;name&gt; is the rdn for ou=Accounts, and cn=&lt;name&gt; for ou=Groups, but Active Directory uses CN=&lt;value&gt; for almost all rdns. What is directory hierarchy?: The data in LDAP is stored in the form of a hierarchical structure (called DIT, i. e, Directory Information Tree). It is just a tree with nodes and leafs, no rocket science! Let’s understand this visually.   The top of the tree is called the basedn (dc=example, dc=com).  Each entry in the tree has one parent entry (object) and zero or more child entries (objects). Each child entry (object) is a sibling of its parent’s other child entries.  Each entry is an instance of one or more objectClasses.  Objectclasses contain zero or more attributes.  Attributes have names and contain data. So, coming back to our query “CN=Alisha,OU=People,DC=example,DC=google,DC=com” It means “From the com domain component, find google Domain Component, and from this find example Domain Component. From the example Domain Component, find People Organisational Unit, and from this find an entry whose common name is Alisha. ” What is DC (Domain Component)?: This refers to each component of the domain. For example, “example. google. com” would be written as DC=example,DC=google,DC=com. What is OU (Organizational Unit)?: This refers to the organizational unit (or sometimes the user group) that the user is part of, for example, a user might be a part of People group or Developer group. If the user is part of more than one group, it can be specified as OU= Developer, OU= Tester. (Many a times, developer might have to do all the testing by himself also, hence both of the groups!) What is CN (Common Name)?: This refers to the individual object (person’s name; meeting room; recipe name; job title; etc. ) for whom/which object you are querying. For example, 1234uid=alisha, ou=People, dc=example, dc=comuid: alishacn: alisha. . . uid is equivalent to user id, so it is a unique user identifier (generally the “logon” name). cn is the “common name” so what I should be “called”. (There is also displayName for applications to render too). Hold on tight, more to come! :) "
    }, {
    "id": 15,
    "url": "http://localhost:4000/evtx/",
    "title": "Parsing Windows event log files (.evtx) using Python",
    "body": "2017/11/25 - Recently I came across a problem in which I had to convert . evtx files (Windows Event Log files) to a human readable format like XML, CSV, JSON etc. There’s this popular and only working parser that I know about python-evtx. It parses . evtx files to XML format. These are the steps which I followed:    Clone the python-evtx directory in your system.   1git clone https://github. com/williballenthin/python-evtx. git      Go into the cloned directory.   1cd python-evtx      Install the libraries   1python3 setup. py install      Go to the scripts directory inside python-evtx.   1cd scripts      Run the following command if you just have one file which you want to convert.   1python3 evtx_dump. py /mnt/data/alisha/logs/dc/security. evtx      In my case, I had folders inside folders which had . evtx files to convert, so I did:   12345for file in $(find /mnt/data/alisha/logs/ -iname  *. evtx )do	python3 evtx_dump. py $file &gt; /mnt/data/alisha/parsed-evtx/`basename  $file `. xml	echo  $file: $?  &gt;&gt; conversion. logdone    It will first check every file inside the logs folder for . evtx extension and run evtx_dump. py on everyfile thereafter storing the . xml in a new folder, i. e. , parsed-evtx. If it is not able to parsea file into XML due to some error, the filename will get saved in conversion. log.   I hope this will help someone!  "
    }, {
    "id": 16,
    "url": "http://localhost:4000/pyladies/",
    "title": "[PyLadies Talk] Introduction to Machine Learning",
    "body": "2017/11/20 - This post is about the talk I gave in PyLadies Melbourne meetup on 20th Nov’17. I gave a beginner introduction to Machine Learning, the common methods and evaluation metrics. Here is the PDF. I have attached below the pdfs of ‘Knowledge Technologies’ subject lectures, projects and sample exam papers, which introduces the concepts of information retrieval, machine learning and data mining. Lecture set 1- Subject Overview Lecture set 2- String Search Lecture set 3- Approximate String Search and Matching Lecture set 4- Text Search Lecture set 5- Web Search Project 1- Back-transliteration of Persian names to English names: github Lecture set 6- Introduction to Machine Learning Lecture set 7- Introduction to Basic Probability Lecture set 8- Data Mining Lecture set 9- Classification Lecture set 10- Decision Trees Lecture set 11- Rule Based Classification and Random Forests Lecture set 12- KNN and Support Vector Machines Lecture set 13- Association Analysis Lecture set 14- Clustering Project 2- Sentiment Analysis on Tweets Sample Exam Paper 1 Sample Exam Paper 2 I cannot provide the datasets for the projects, but the project specifications will give a brief idea and you can find similar datasets online :) "
    }, {
    "id": 17,
    "url": "http://localhost:4000/mlai/",
    "title": "[MLAI Meetup Talk] My Experience as a Machine Learning Intern",
    "body": "2017/10/18 - I started my internship at SilverPond as a Machine Learning Engineer in September. I spent initial few weeks getting familiar with Silverbrane. Silverbrane is an amazing Machine Learning product developed by an amazing team at SilverPond which combines optimised expert-driven tooling with AI, which in brief does this: Project 1:My first project was “Server provisioning in Silverbrane”. I had to provision the server to automatically spin the workers to start training the model, which was previously a manual process. By the end of it, I learnt about:  Managing AWS ec2 instances using console Managing AWS ec2 instances using programming (using aws-sdk for ruby) How Ruby on Rails project is structured Finding my way inside a rails project (Though I still don’t understand Rails or Ruby much!)Project 2:At the moment, I am working on an another project in which we “Count the number of cars in overhead imagery with deep learning”. This project tries to replicate the results presented in this paper: Mundhenk et al. 2016 Vehicle localization from satellite imagery has myriad use cases in the commercial, national security, and humanitarian realms. On the commercial front, a number of companies have attempted to infer retail traffic from parking lot density levels, and tracking delivery trucks in near real-time is one of the far-field goals of satellite imagery analytics. In the realm of national security, detecting the buildup of war materiel in unstable regions would provide obvious value, as would locating convoys of vehicles vectored towards unmanned border crossings, or identifying a large number of vehicles staging just outside the range of terrestrial border monitoring equipment. On the humanitarian front, one might attempt to infer the scope of natural disasters from clusters (or absences) of vehicles, or determine optimal travel routes for disaster relief in unknown areas based on observations of local vehicle movements. Dataset The dataset consists of large number of unique cars (~33,000) from six different imagesets, where each imageset has more than 60,000 images. Each imageset covers a different geographical location and produced by different imagers and has different training and test sets. The regions are Toronto Canada, Selwyn New Zealand, Potsdam &amp; Vaihingen Germany, Columbus &amp; Utah United States. Data is collected via aerial platforms, but at a view angle such that it resembles satellite imagery. The imagery has a resolution of 15 cm ground sample distance (GSD) that is approximately twice as good as the current best resolution of commercial satellite imagery. Dataset consists of images like these: Approach::  I started by using inception model to classify the images, though it is not really good at classifying correctly, since it is a baseline model. I downloaded a pre-trained inception model, since it takes weeks to train on a monster computer with 8 Tesla K40 GPUs costing ~$30,000 so it is impossible to train it on an ordinary PC.  I trained the model by logistic regression using scikit-learn. It is a multi way classification where we have 64 classes (the maximum number of cars that are in any image/patch is 64).  I took the training and test set together and later split it.  With close to 1 million images, the accuracy achieved was ~55%.  But if all the images from training and test set is taken it would take approx. 2 days to train the model.  So,I trained the model by logistic regression using Tensorflow, where I took the image in batches (say, 50).  With close to 40,000 images, The accuracy achieved was ~48%. But the methodology mentioned in the paper is able to achieve an accuracy of ~80%. How may we increase the accuracy? ( Have to try these out, once I do, I will update the post):  Instead of inception model, use a different model, like Resception, Mundhenk et al. 2016 Reserve the Utah region (both training and test) for training purposes as it differs significantly in car density, building architecture, &amp; vegetation patterns from regions in Germany, New Zealand, and Canada, hence provides a rigorous training case.  Run on the validation set provided by the authors of the paper. By the end of the internship, I expect to…:  Get intermediate experience with deep learning frameworks like Tensorflow &amp; Pytorch and machine learning libraries like scikit-learn.  Get more familiar with various deep learning approaches.  Be proficient in skimming through research papers and apply the methodologies to practical projects (Because reading research papers is so damn boring!).  Build a foundation to become a machine learning engineer after my graduation!I will update the code on Github as well once I complete the project. I gave this talk at the Melbourne MLAI meetup. This is the Meetup link. Hope you enjoyed it! :) "
    }, {
    "id": 18,
    "url": "http://localhost:4000/custom-rails/",
    "title": "Custom Links within ActiveAdmin Pages - Ruby on Rails",
    "body": "2017/10/04 - I am working on a Ruby on Rails project in my organization and I am very new to Rails. It took me days to find a way for creating custom buttons and their methods alongside the default ‘Edit, View, Delete …. . ’ buttons. I finally found a fix to this and I concluded that Rails does really magical stuff behind the scenes which isn’t obvious to a new programmer. So, to give an overview of my task – I am working on creating an ‘Instances’ tab on the ActiveAdmin index page. This instance page will list all of the current available AWS EC2 instances, and a link to VIEW, EDIT, DELETE (already available ones), STOP and REBOOT (custom ones, which I needed to make). This is how my page looks after adding the custom links: Oh and I removed the ‘EDIT’ link, I will show this as well. This one is pretty straighforward though. So for adding the custom links: 1234567891011index do   selectable_column   id_column   column :image_id   column :min_count   column :max_count   column :monitoringcolumn() { |instance| link_to 'Stop', stop_admin_instance_path(instance), method: :post }column() { |instance| link_to 'Reboot'}   actionsendWe are creating these links in the seperate columns, with the name ‘Stop’, redirect path as “/admin/instances/stop”, which Rails already has a helper for, nameOfMethod_admin_pageName_path(your_record), and the request method (GET/POST/PUT/DELETE). Similarly, it goes for ‘Reboot’ a well. To check this helper route, run rake routes from the console. Now, we will add the method for stop button, which goes like this: 12345member_action :stop, method: :post do    instance = Instance. find(params[:id])    AwsService. stop_ec2_instance(instance. instance_id)    redirect_to  /admin/instances/ endI have made an AWS Service to stop the instances, using aws-ruby sdk, but that’s out of the scope of this post. params(:id) will send the id of the record on which this method would be called, to the find method, to find this record from the table and then the further instructions will be carried out on the record. And to remove the default edit link, I did as follows: 123controller do    actions :all, :except =&gt; [:edit]endBasically, in the controller section, you specify that all actions take place except the edit one’. If you wanted to remove, for example, delete action, you would just have to add delete similarly as the edit action. I hope this would help someone :) "
    }, {
    "id": 19,
    "url": "http://localhost:4000/codecamp/",
    "title": "Keep Calm and go to Code Camp!",
    "body": "2017/09/29 - Code Camp is a fun coding camp of 2, 3 and 4 days where children learn to code. They get a hands-on experience of what coding is. Now some pictures!   The classes are divided into 4 groups: Little League: This group is for kids aged between 5 - 6 or who are in grades K - 1 and who have no idea of what coding is.  Each Little League camp comes equipped with iPads for the whole class to enjoy. The kids build awesome mini-games and learn about coding in the process. This group is a combination of online and offline activities. For more info, check here: Little-league. Spark: This group is for kids aged between 7 - 12 or who are in grades 2 - 6 with beginner’s knowledge and are ready to hop on to intermediate stage. This is the most popular group. They make their own mobile phone game playable via the Code Camp App (which can be downloaded on Apple and Android phones). The kids get a taste of real world coding by doing ‘Drag and Drop’ coding using the proprietory software ‘Code Camp World’. This is even accessible after the camp ends, so they can practice and have fun at home too, taking help from the video tutorials! For more info, check here: spark. Ignite: This group is for kids aged between 7 - 12 or who are in grades 2 - 6 with intermediate knowledge and are ready to hop on to advanced stage. They make their own mobile phone game playable via the Code Camp App (which can be downloaded on Apple and Android phones). The kids get a taste of real world coding by doing advanced ‘Drag and Drop’ coding and line coding using Javascript on the last day of the camp using the proprietory software ‘Code Camp World’. This is even accessible after the camp ends, so they can practice and have fun at home too, taking help from the video tutorials! For more info, check here: ignite. Blast: This group is for kids aged between 8 - 13 or who are in grades 3 - 7 and have completed the Spark and Ignite. This is for advanced students only as they learn coding in pure Javascript. They make their own mobile phone game playable via the Code Camp App (which can be downloaded on Apple and Android phones), using line coding in pure Javascript. For more info, check here: blast. &lt;/br&gt; Each class has a staff of atleast three people, including head teacher and teaching assistants. Each camp has atleast two camp managers and a first aid practitioner. I was a teaching assistant for the Ignite group in the camp conducted at University of Melbourne during the spring holidays 2017. There was a Code Camp meet and greet two weeks before the camp to prepare the staff for their respective roles. There was a party as well, so that the staff can know each other well. I didn’t go, so I can’t elaborate on how it was :P It was a three day camp, and I had a lot of fun. I love kids, I love teaching and I love coding (obviously, being a software programmer myself!). It is a very fulfilling role, where you know you are building the foundation for technologists of the future. I saw the amazed look on people’s face due to the response they got for the question ‘what the camp is for’, keeping in mind that all kids were of age group 5 - 13, with average age being 9. The timings for the camp were 9 am - 3. 30 pm. On the first day, all the kids were provided with a Code Camp t-shirt and a hat. As far as learning is concerned, they learnt Drag and Drop coding in the Code Camp World software, where they could keep practicing at home as well. There were two breaks in between, a recess and a lunch break so that the kids can have some outdoor time and get refreshed. The day ended with a cheerful note, with all the kids being happy about the exciting things they learnt during the day. On the second day, the kids were taught about some advanced concepts in Drag and Drop coding like logic, UI, Math functions etc. They made many mini games inside the main game using these concepts. On the third and the last day, they finished their mini games using Drag and Drop and made another mini game using line coding only, i. e. using Javascript. An unexpected observation was that the kids found line coding more fun and easier than the Drag and Drop coding (i. e. Block Coding)! During the lunch break, there was a silent disco party where all the teachers and kids were provided with headphones playing some great classic party tracks ;) All the games were published by 3 pm on the Code Camp portal and the students showcased their games and even challenged their friends to complete various levels in their games. The games can be accessed from the Code Camp app. Each kid gets a code and using that code, one can find his/her game in the app. Here is an example screenshot for the same: At the end of the day, everyone had mixed feelings, as it was an exciting experience but saying goodbyes is always the hardest part. Here are some screenshots of the games made by the kids during the camp:   I hope you enjoyed reading the post. Thanks! Tada! :) "
    }, {
    "id": 20,
    "url": "http://localhost:4000/hde-interview/",
    "title": "Interview Experience with HDE Inc.",
    "body": "2017/09/02 - HDE Inc. is a Japanese Cloud Security Provider established in 1996 and their Global Internship Program (GIP) has become very popular in recent times. Some benefits of this internship:  Up to 150,000 JPY/month subsidy. The subsidy is given to cover living costs such as meals, commuting expense, and accommodation.  Round-trip airfares coverage Medical insuranceFor more info, refer this link: HDE GIP The process was as follows: (as of June 2017)  Programming Test Online Interview Offer Letter (if successful!)Let’s have a look at all these components one by one: PROGRAMMING TEST: The programming test involved writing a program in Golang, which was not exactly easy. It required some thinking because I found Golang a very limited language as compared to Python (I have mostly programmed in Python). To send this program to HDE, it involved writing another program for which I had to go through technical RFC documentations (to do authentication and generate password etc. ). In the end, I had to make use of requests and HTTP to actually hit the HDE’s API to send them the program. The program had to be written in a private gist (so knowledge of Github is essential). DO NOT CHEAT. Because even if you are successful at this stage, at the next stage you will be eliminated if you cheat because in the interview they actually ask questions about the program. I succeeded in the programming test! I was informed about the schedule of the online interview within 2 weeks. ONLINE INTERVIEW: The online interview was conducted on Skype. It was more like a behavioral one. There were three interviewers and all were very friendly. We even talked about sushis! They asked questions about some open source projects of mine, challenges that I faced while programming and general questions about my willingness to travel to Japan and University subjects etc. Just be yourself, don’t be nervous, answer questions honestly. If you don’t know something, say ‘no’ straight away. P. S. - It will be good if you know Python or Golang because their projects are mostly in these technologies. OFFER LETTER: I received the offer letter within two weeks. I had to choose an internship slot. The department is Cloud Product Development Division. Each internship slot is approximately of 6 weeks, and this program runs all year round. A candidate is free to select any time frame which suits him/her. The HR was cooperative as well. Overall, it was a smooth experience. Will update my internship experience once I start. There’s still time in it. :P EDIT : HDE team visited Melbourne and we had a nice dinner at +39 Pizzeria on 14th Sept’17. It was an informal meeting and the peeps from HDE were so friendly. I didn’t feel even for a second that I was meeting them for the first time. We clicked some pics as well, though not really high quality ones but yeah, manageable! :P "
    }, {
    "id": 21,
    "url": "http://localhost:4000/first-week/",
    "title": "First Week of Machine Learning Internship at SilverPond",
    "body": "2017/08/27 - I joined SilverPond as a Machine Learning Intern under the Victorian Chamber Internship Program. It was an interesting opportunity and I was very excited for it since working with data has always intrigued me.  SilverPond is a team of data scientists, machine learning specialists, software engineers and mathematicians who design solutions to hard problems. For over 13 years, they have developed big data and software solutions for clients in various industries ranging from utilities, retail, and technology, to healthcare, education and research like Australia Post and 7-11. They are also actively involved in sharing knowledge about Artificial Intelligence, Machine Learning, and various other technologies by hosting meetups and conferences. Compose:: Melbourne (Functional Programming Conference) is supported and managed by SilverPond its team members. They are also holding a 2-day Deep Learning Workshop on 5th and 6th Dec’17. The curriculum looks pretty interesting for anyone who would like to supplement their Data Science learning. The details can be found here: Deep Learning Workshop. My first day involved creating accounts across various mediums that Silverpond uses for collaboration like Asana (just like Trello), Slack, Gitlab and conventional email account and setting up the in-house project, Silverbrane. While setting up, some issues cropped up but eventually I resolved it and added these in the documentation. But it’s technology stack involves Ruby on Rails, in which I am not really proficient, so my first step involved getting familiar with the main functioning of the project and Ruby (of course!). The next day I found some bugs in Silverbrane and picked up one to resolve which I did but now I am struggling with fixing test for it in RSpec (which I hope to resolve soon). Every team member at SilverPond was very welcoming and made sure that I felt at ease on the very first day. Next week would be interesting because I hope to dive into a bit of Machine Learning part of the Silverbrane. Also, I would be volunteering for the Compose:: Melbourne (28th-29th Aug’17), which would be surely an enriching experience. I would share my second week internship experience and the highlights of Compose:: Melbourne soon! :) "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});